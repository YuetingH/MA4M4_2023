{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad15e279",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preliminaries\" data-toc-modified-id=\"Preliminaries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preliminaries</a></span></li><li><span><a href=\"#Basic-structural-properties-of-networks\" data-toc-modified-id=\"Basic-structural-properties-of-networks-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Basic structural properties of networks</a></span></li><li><span><a href=\"#Random-graph-models\" data-toc-modified-id=\"Random-graph-models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Random graph models</a></span></li><li><span><a href=\"#Community-Structure-[Optional]\" data-toc-modified-id=\"Community-Structure-[Optional]-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Community Structure [Optional]</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963a9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic packages\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe9585",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb2d8b",
   "metadata": {},
   "source": [
    "1. Download data for at least one relatively small **unweighted and undirected network** of somewhat different sizes from [Konect](http://konect.cc/) and have a look at the data format. Import the network data into your interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef8f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa55b023",
   "metadata": {},
   "source": [
    "2. Visualize the network & corresponding adjacency matrix. \n",
    "\n",
    "   Note that if you would like a pretty network visualisation using NetworkX, here is a useful [link](https://networkx.org/documentation/stable/auto_examples/drawing/plot_directed.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74835c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "996fcc5c",
   "metadata": {},
   "source": [
    "# Basic structural properties of networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b950c7",
   "metadata": {},
   "source": [
    "**In this section, we focus on one of the unweighted and undirected networks above, except for the first question which requires an additional directed and weighted network.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ef92f",
   "metadata": {},
   "source": [
    "1. Compute the degree distribution and visualize its histogram.\n",
    "\n",
    "    What is the mean and variance of the degrees? \n",
    "    \n",
    "    Repeat the same exercise for a directed network, and a weighted network downloaded from [Konect](http://konect.cc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c5354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c70d8ef1",
   "metadata": {},
   "source": [
    "2. Compute the local clustering coefficient, closeness centrality, and betweenness centrality of nodes in the network.\n",
    "\n",
    "    Measure the correlation between degrees, betweenness, and closeness centrality. The correlation can either be estimated with the centrality values (Pearson) or with their associated ranking (Kendall’s tau or Spearman’s rho). \n",
    "    \n",
    "    Some useful code (ignore the redness):\n",
    "    ```python\n",
    "    nx.clustering(G)                           # Local clustering coefficient\n",
    "    nx.closeness_centrality(G)                 # Closeness centrality\n",
    "    nx.betweenness_centrality(G)               # Betweenness centrality\n",
    "    \n",
    "    np.corrcoef(data1, data2)                  # Pearson correlation\n",
    "    coef, p = stats.kendalltau(x1, x2)         # Kendall’s tau\n",
    "    coef, p = stats.spearmanr(data1, data2)    # Spearman’s rho\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c24c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ef3cf43",
   "metadata": {},
   "source": [
    "3. Create two visualizations for the empirical networks (i) nodes are colored based on degree and (ii) nodes are colored based on betweenness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fabb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c549272a",
   "metadata": {},
   "source": [
    "4. Find the shortest path between all pairs of nodes. (Use ```nx.shortest_path(G)```) \n",
    "\n",
    "    What algorithm is the built-in function using? (Useful [link](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.shortest_paths.generic.shortest_path.html))\n",
    "    \n",
    "    Now, compute the number of components in the network, delete the 5% of nodes with highest betweenness centrality, and recompute the number of components. Has it changed? (Use ```G.remove_node(node_to_remove)```. Note that it's better for you to copy and create a new graph ```G_copy = G.copy()``` and remove nodes from this new graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd8b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e610b00f",
   "metadata": {},
   "source": [
    "5. Numerically compute the eigenvalues of the adjacency matrix, the (combinatorial) Laplacian matrix and the normalised Laplacian matrix of the empirical network. \n",
    "\n",
    "    Verify the relationship between the number of components and the number of 0 eigenvalues of the Laplacian. \n",
    "    \n",
    "    What can be said about the range of the eigenvalues of the normalised Laplacian matrix?\n",
    "    \n",
    "    Useful code:\n",
    "    ```python\n",
    "    adj = nx.adjacency_matrix(G); adj = adj.toarray()  # Adjacency matrix\n",
    "    adj_eig = np.linalg.eig(adj)[0]                    # Eigenvalues of the adjacency matrix\n",
    "    \n",
    "    from scipy.sparse import csgraph\n",
    "    L_arr = csgraph.laplacian(adj_arr, normed=True)    # Normalised Laplacian matrix\n",
    "    L_eig = np.linalg.eig(L_arr)[0]                    # Eigenvalues of the normalised Laplacian matrix\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b67c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f191fef0",
   "metadata": {},
   "source": [
    "# Random graph models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac53d0",
   "metadata": {},
   "source": [
    "1. Consider an unweighted and undirected empirical network G. Generate \n",
    "    \n",
    "    (i) an Erdös-Rényi graph with an expected total edge weight equal to the total edge weight in G\n",
    "    \n",
    "    (ii) a configuration random graph with the same degree sequence as G.\n",
    "    \n",
    "    Useful code:\n",
    "    \n",
    "    ```python\n",
    "    nx.erdos_renyi_graph(n, p)            # n: the number of nodes; p: probability for edge creation.\n",
    "    nx.configuration_model(deg_sequence)     \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2cd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92833a29",
   "metadata": {},
   "source": [
    "2. Sample networks (e.g., sample degree sequence from a power-law distribution) of increasing node set size from the configuration model. Compute the density of self-edges and multiedges for the different samples. (Useful [link](https://stackoverflow.com/questions/29095070/how-to-simulate-from-an-arbitrary-continuous-probability-distribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ad577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89bec41f",
   "metadata": {},
   "source": [
    "3. Generate a network using the BA model. (Use ```nx.barabasi_albert_graph(n, m)```. Figure out what $n$ and $m$ stand for.)\n",
    "\n",
    "    Plot the resulting degree distribution and visualize the resulting network with nodes coloured by their degree (as in 2c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5339543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21109f0c",
   "metadata": {},
   "source": [
    "# Community Structure [Optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62985da",
   "metadata": {},
   "source": [
    "A partition of a network is a division of nodes into sets. For example {{1, 2, 3}, {4, 5}} is a partition of 5 nodes into two sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef164f3",
   "metadata": {},
   "source": [
    "1. Consider the matrix given by $B = A − (kk^T )/2M$ , where $k$ is an *N* × 1 vector with ith entry $k_i$. This matrix is often referred to as the modularity matrix and forms the basis for a very popular clustering method in network science known as modularity maximization. \n",
    "\n",
    "    Import the Karate Club network from Konect and compute its modularity matrix. (Use ```B = nx.modularity_matrix(G)```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ac9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "429638d4",
   "metadata": {},
   "source": [
    "2. Compute the leading eigenvector $v_1$ of the modularity matrix of the Karate Club and assign nodes to two sets\n",
    "(thus obtaining what is known as a bipartition) as follows: node $i$ is in set 1 if $v_{1i}$ ≥ 0 and node $i$ is in set 2 otherwise, with $v_{1i}$ the ith entry of $v_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5e827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fda6c84",
   "metadata": {},
   "source": [
    "3. Write a function that takes as input a modularity matrix and a bipartition, and returns the following quantity as an output: $ \\sum_{i, j \\text{ in same set}} B_{ij}$\n",
    "\n",
    "    Compare the value of the above quantity for the partition as defined in 4b, and a partition where nodes are assigned to two sets uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5c153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181d8ac1",
   "metadata": {},
   "source": [
    "4. Visualize the Karate Club network with nodes coloured based on their set assignment as obtained in 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17551a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
